{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: SAT & ACT Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will be exploring what can data tell us about SAT and ACT participation rates and what College Board can do to increase participation rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "The SAT and ACT are widely used standardized tests taken in the US for the purpose of College admission. Data pertaining to these tests were split into state means, and have been thoroughly analyzed.\n",
    "\n",
    "Through analysis, it has been found that a high participation rate for SAT correlates with a low ACT participation rate, and vice versa. Low participation rates have also been found to correlate with a higher scores all around for that specific test.\n",
    "\n",
    "Further research has shown that the best way to increase SAT participation is to make it mandatory state-wide.\n",
    "\n",
    "Datasets have been provided by the team at GA and consists of 'sat_2017.csv', 'act_2017.csv', 'sat_2018.csv', and 'act_2018_updated.csv'\n",
    "\n",
    "2017 data from provided links have also been compiled into csv files: 'sat_2017_fromweb.csv' and 'act_2017_fromweb.csv'\n",
    "\n",
    "### Contents:\n",
    "- [2017 Data Import & Cleaning](#2017-Data-Import-and-Cleaning)\n",
    "- [2018 Data Import and Cleaning](#2018-Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-data)\n",
    "- [Descriptive and Inferential Statistics](#Descriptive-and-Inferential-Statistics)\n",
    "- [Outside Research](#Outside-Research)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you combine your problem statement, executive summary, data dictionary, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.** Don't forget to cite your data sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports:\n",
    "import numpy as np # Import numpy library as alias np\n",
    "import pandas as pd # Import pandas library as alias pd\n",
    "import matplotlib.pyplot as plt # Import matplotlib.pyplot library as alias plt\n",
    "import seaborn as sns # Import seaborn library as alias sns\n",
    "from scipy import stats # Import stats library from scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017 Data Import and Cleaning\n",
    "* [1. Read In SAT & ACT Data](#1.-Read-In-SAT-&-ACT--Data)\n",
    "* [2. Display Data](#2.-Display-Data)\n",
    "* [3. Verbally Describe Data](#3.-Verbally-Describe-Data)\n",
    "* [4a. Does this data look complete?](#4a.-Does-the-data-look-complete?)\n",
    "* [4b. Are there any obvious issues with the observations?](#4b.-Are-there-any-obvious-issues-with-the-observations?)\n",
    "* [4c. Fix any errors you identified](#4c.-Fix-any-errors-you-identified)\n",
    "* [4c.1 Fixing Sat Errors](#4c.1-Fixing-SAT-Errors)\n",
    "* [4c.2 Fixing ACT Errors: Bad Science Value](#4c.2-Fixing-ACT-Errors:-Bad-Science-Value)\n",
    "* [4c.3 Fixing ACT Errors: Bad Composite Value](#4c.3-Fixing-ACT-Errors:-Bad-Composite-Value)\n",
    "* [5. What are your data types?](#5.-What-are-your-data-types?)\n",
    "* [6. Fix Incorrect Data Types](#6.-Fix-Incorrect-Data-Types)\n",
    "* [7. Rename Columns](#7.-Rename-Columns)\n",
    "* [8. Create a data dictionary](#8.-Create-a-data-dictionary)\n",
    "* [9. Drop unnecessary rows](#9.-Drop-unnecessary-rows)\n",
    "* [10. Merged Dataframes](#10.-Merge-Dataframes)\n",
    "* [11. Save your cleaned, mearged dataframe](#11.-Save-your-cleaned,-merged-dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read In SAT & ACT  Data\n",
    "\n",
    "Read in the `sat_2017.csv` and `act_2017.csv` files and assign them to appropriately named pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and assigning the datasets to appropriately named pandas dataframes\n",
    "pan_sat_2017 = pd.read_csv('../data/sat_2017.csv') # Test data obtained from GA git\n",
    "pan_act_2017 = pd.read_csv('../data/act_2017.csv') # Test data obtained from GA git\n",
    "pan_sat_2017_from_web = pd.read_csv('extradatasets/sat_2017_fromweb.csv') # *Data obtained from weblink given by Ryan through slack\n",
    "pan_act_2017_from_web = pd.read_csv('extradatasets/act_2017_fromweb.csv') # *Data obtained from weblink given by Ryan through slack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>*The \"_fromweb\" csv files contain data pulled from the weblinks provided by Ryan through slack:</em>\n",
    "* https://www.act.org/content/dam/act/unsecured/documents/cccr2017/ACT_2017-Average_Scores_by_State.pdf\n",
    "* https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Display Data\n",
    "\n",
    "Print the first 10 rows of each dataframe to your jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 10 lines of panda dataframe 'pan_sat_2017'\n",
    "pan_sat_2017.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 10 lines of panda dataframe 'pan_act_2017'\n",
    "pan_act_2017.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Verbally Describe Data\n",
    "\n",
    "Take your time looking through the data and thoroughly describe the data in the markdown cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "From first observation - \n",
    "* It appears that there is a very wide range of values for \"participation\", with Alabama having a participation rate of 5% and states like Connecticut having a 100% participation rate for the SAT.\n",
    "* It appears that the paticipation % sum of both tests add up to close to 100%, meaning that having a lower participation rate in one test, will lead to a higher participation rate in the other. However, more information has to be known to make that conclusion.\n",
    "    * We will need to see if both tests are using the same number of people to calculate participation, and also to see if the other states confirm this observation\n",
    "* It appears that a lower participation rate in either test, may correlate with higher scores for that specific test.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. Does the data look complete? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if the data is complete, we will be utilizing the .isnull() function and .info() function on both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'pan_sat_2017' dataframe for null characters, and summing the number of null characters\n",
    "pan_sat_2017.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'pan_act_2017' dataframe for null characters, and summing the number of null characters\n",
    "pan_act_2017.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at dataframe information for the 'pan_sat_2017' dataframe\n",
    "pan_sat_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looking at dataframe information for the 'pan_act_2017' dataframe\n",
    "pan_act_2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "The data appears to be complete, however the data types may need to be cleaned/converted.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Are there any obvious issues with the observations?\n",
    "\n",
    "**What is the minimum *possible* value for each test/subtest? What is the maximum *possible* value?**\n",
    "\n",
    "Consider comparing any questionable values to the sources of your data:\n",
    "- [SAT](https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/)\n",
    "- [ACT](https://blog.prepscholar.com/act-scores-by-state-averages-highs-and-lows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the describe function on 'pan_sat_2017', to see if there are any abnormal values. \n",
    "# The result is rounded to 2 decimal places with the 'round' function.\n",
    "round(pan_sat_2017.describe(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the describe function on 'pan_act_2017', to see if there are any abnormal values. \n",
    "# The result is rounded to 2 decimal places with the 'round' function.\n",
    "round(pan_act_2017.describe(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan_act_2017.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "For the SAT, each section can have a value from a minimum value of 200 to a maximum value of 800. In this dataset, we see that the minimum for math is 52. This means that we will need to clean this data.\n",
    "\n",
    "For the ACT, it appears that the ACT composite scores did not show up when using the describe function. This could mean that the composite scores were stored as a string. This could be because Wyoming has an additional x behind the value.\n",
    "\n",
    "The minimum and maximum values fall between the possible range of 1 to 36 for each section. However, upon closer inspection we see that the science scores for Maryland is around 10 times less than the science scores for every other state. This dataset will also need to be cleaned.\n",
    "\n",
    "<em>Note: Data was ammended utilizing the \"_fromweb\" csv files which contains data pulled from updated weblinks that were provided by Ryan though slack.</em>\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c. Fix any errors you identified\n",
    "\n",
    "**The data is available** so there's no need to guess or calculate anything. If you didn't find any errors, continue to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4c.1 Fixing SAT Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset 'pan_sat_2017' for values in the 'Math' column that are less than 200\n",
    "pan_sat_2017[pan_sat_2017['Math']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset 'pan_sat_2017_from_web' for values in the 'State' column that is equal to 'Maryland'\n",
    "pan_sat_2017_from_web[pan_sat_2017['State']=='Maryland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the correct data from the dataset 'pan_sat_2017_from_web' to 'pan_sat_2017'\n",
    "pan_sat_2017.loc[20, 'Math'] = pan_sat_2017_from_web['Math'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset 'pan_sat_2017' for values in the 'Math' column that are less than 200\n",
    "# Just to double check that the error has been fixed\n",
    "pan_sat_2017[pan_sat_2017['Math']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset 'pan_sat_2017' for values in the 'State' column that is equal to 'Maryland'\n",
    "# Just to double check that saved value is correct\n",
    "pan_sat_2017[pan_sat_2017['State']=='Maryland']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "Steps taken in this section is as follows - \n",
    "1. Check which values in the 'pan_sat_2017' dataset have a math value that is below the minimum (200)\n",
    "2. Check the corresponding row in the 'pan_sat_2017_from_web' dataset\n",
    "3. Assigned the correct value from 'pan_sat_2017_from_web' to 'pan_sat_2017'\n",
    "4. Check to ensure that there are no longer math values in the 'pan_sat_2017' dataset that falls below the minimum (200)\n",
    "5. Check to ensure that the correct value for math has been stored in the 'pan_sat_2017' dataset\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4c.2 Fixing ACT Errors: Bad Science Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset 'pan_act_2017' for values in the 'Science' column that are less than 5\n",
    "pan_act_2017[pan_act_2017['Science']<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset 'pan_act_2017_from_web' for values in the 'State' column that is equal to 'Maryland'\n",
    "pan_act_2017_from_web[pan_act_2017_from_web['State']=='Maryland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the correct data from the dataset 'pan_sat_2017_from_web' to 'pan_sat_2017'\n",
    "pan_act_2017.loc[21, 'Science'] = pan_act_2017_from_web['Science'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset 'pan_act_2017' for values in the 'Science' column that are less than 5\n",
    "# Just to double check that the error has been fixed\n",
    "pan_act_2017[pan_act_2017['Science']<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset 'act_sat_2017' for values in the 'State' column that is equal to 'Maryland'\n",
    "# Just to double check that saved value is correct\n",
    "pan_act_2017[pan_act_2017['State']=='Maryland']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "Steps taken in this section is as follows - \n",
    "1. Check which values in the 'pan_act_2017' dataset have a math value that is below 5\n",
    "2. Check the corresponding row in the 'act_sat_2017_from_web' dataset\n",
    "3. Assigned the correct value from 'pan_act_2017_from_web' to 'pan_act_2017'\n",
    "4. Check to ensure that there are no longer 'Science' values in the 'pan_act_2017' dataset that falls below 5\n",
    "5. Check to ensure that the correct value for 'Science' has been stored in the 'pan_act_2017' dataset\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4c.3 Fixing ACT Errors: Bad Composite Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing list comprehension to apply a mask to 'pan_act_2017' to find values in 'Composite' column that contain 'x'\n",
    "pan_act_2017[[True if 'x' in cell else False for cell in pan_act_2017['Composite']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset 'pan_act_2017_from_web' for values in the 'State' column that is equal to 'Wyoming'\n",
    "pan_act_2017_from_web[pan_act_2017_from_web['State']=='Wyoming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the correct data from the dataset 'pan_sat_2017_from_web' to 'pan_sat_2017'\n",
    "pan_act_2017.loc[51, 'Composite'] = pan_act_2017_from_web['Composite'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing list comprehension to apply a mask to 'pan_act_2017' to find values in 'Composite' column that contain 'x'\n",
    "# Just to double check that the error has been fixed\n",
    "pan_act_2017[pan_act_2017['State']=='Wyoming']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "Steps taken in this section is as follows - \n",
    "1. Check which values in the 'pan_act_2017' dataset have a 'Composite' value that contains x\n",
    "2. Check the corresponding row in the 'act_sat_2017_from_web' dataset\n",
    "3. Assigned the correct value from 'pan_act_2017_from_web' to 'pan_act_2017'\n",
    "4. Check to ensure that the correct value for 'Composite' has been stored in the 'pan_act_2017' dataset\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are your data types? \n",
    "Display the data types of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing the .info() function to check data types of 'pan_sat_2017'\n",
    "pan_sat_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing the .info() function to check data types of 'pan_act_2017'\n",
    "pan_act_2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you learn?\n",
    "- Do any of them seem odd?  \n",
    "- Which ones are not as they should be?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "* It appears that participation in both the SAT and ACT dataframe is stored as an object instead of a float\n",
    "* It appears that composite in the ACT dataframe is stored as an object, instead of a float\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fix Incorrect Data Types\n",
    "Based on what you discovered above, use appropriate methods to re-type incorrectly typed data.\n",
    "- Define a function that will allow you to convert participation rates to an appropriate numeric type. Use `map` or `apply` to change these columns in each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that tries to return a float, else it will return NaN\n",
    "def to_float(x):\n",
    "    \"\"\"Function tries to return a float, else it will return NaN\"\"\"\n",
    "    try:\n",
    "        out = float(x)\n",
    "    except:\n",
    "        out = np.nan\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing the .apply function to change values in column 'Composite' to float\n",
    "pan_act_2017['Composite'] = pan_act_2017['Composite'].apply(to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing the .info() function to check data types\n",
    "pan_act_2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix any individual values preventing other columns from being the appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utilizing the .str.replace function to replace the '%' character with '' for both 'pan_act_2017' and 'pan_sat_2017'\n",
    "pan_act_2017['Participation'] = pan_act_2017['Participation'].str.replace('%', '')\n",
    "pan_sat_2017['Participation'] = pan_sat_2017['Participation'].str.replace('%', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing the .apply function to change values in column 'Participation' to float for both 'pan_act_2017' and 'pan_sat_2017'\n",
    "pan_act_2017['Participation'] = pan_act_2017['Participation'].apply(to_float)\n",
    "pan_sat_2017['Participation'] = pan_sat_2017['Participation'].apply(to_float)\n",
    "\n",
    "# Utilizing the .apply function to change values in columns 'Evidence-Based Reading and Writing', 'Math', and 'Total' for more\\\n",
    "# consistent data types\n",
    "pan_sat_2017['Evidence-Based Reading and Writing'] = pan_sat_2017['Evidence-Based Reading and Writing'].apply(to_float)\n",
    "pan_sat_2017['Math'] = pan_sat_2017['Math'].apply(to_float)\n",
    "pan_sat_2017['Total'] = pan_sat_2017['Total'].apply(to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the data types again to confirm they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing the .info() function to check data types\n",
    "pan_sat_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing the .info() function to check data types\n",
    "pan_act_2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish your data modifications by making sure the columns are now typed appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing the .str.replace function to replace the ' ' character with '_' for both 'pan_act_2017' and 'pan_sat_2017'\n",
    "pan_sat_2017.columns= pan_sat_2017.columns.str.lower().str.replace(\" \",\"_\")\n",
    "pan_act_2017.columns= pan_act_2017.columns.str.lower().str.replace(\" \",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing the .columns function to check column names of 'pan_sat_2017'\n",
    "pan_sat_2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the 'evidence-based_reading_and_writing' column name to 'ebrw' in the 'pan_sat_2017' dataset by utilizing .rename\n",
    "pan_sat_2017.rename(columns={\n",
    "    'evidence-based_reading_and_writing' : 'ebrw',\n",
    "},inplace=True)\n",
    "pan_sat_2017.head() # Display the first 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Rename Columns\n",
    "Change the names of the columns to more expressive names so that you can tell the difference the SAT columns and the ACT columns. Your solution should map all column names being changed at once (no repeated singular name-changes). **We will be combining these data with some of the data from 2018, and so you should name columns in an appropriate way**.\n",
    "\n",
    "**Guidelines**:\n",
    "- Column names should be all lowercase (you will thank yourself when you start pushing data to SQL later in the course)\n",
    "- Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`.\n",
    "- Column names should be unique and informative (the only feature that we actually share between dataframes is the state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing list comprehension to concatenate the column names in the dataset 'pan_sat_2017' with '_sat_2017'\n",
    "pan_sat_2017.columns = [column_name+'_sat_2017' for column_name in pan_sat_2017.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first five rows of the dataframe 'pan_sat_2017'\n",
    "pan_sat_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing list comprehension to concatenate the column names in the dataset 'pan_act_2017' with '_act_2017'\n",
    "pan_act_2017.columns = [column_name+'_act_2017' for column_name in pan_act_2017.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first five rows of the dataframe 'pan_act_2017'\n",
    "pan_act_2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create a data dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|state_act_2017|object|ACT 2017|The state in which the ACT was taken in. Data reflected is from 2017.|\n",
    "|participation_act_2017\t|float|ACT 2017|The ACT participation rate of eligible students in the state  in 2017. This is a percentage value saved as a float, with a maximum value  of 100, which means 100%.|\n",
    "|english_act_2017|float|ACT 2017|The average score across the state for the english section of the ACT in 2017. This value ranges from 1 to 36.|\n",
    "|math_act_2017|float|ACT 2017|The average score across the state for the math section of the ACT in 2017. This value ranges from 1 to 36.|\n",
    "|reading_act_2017|float|ACT 2017|The average score across the state for the reading section of the ACT in 2017. This value ranges from 1 to 36.|\n",
    "|science_act_2017|float|ACT 2017|The average score across the state for the science section of the ACT in 2017. This value ranges from 1 to 36.|\n",
    "|composite_act_2017|float|ACT 2017|The average overall ACT score across the state in 2017. This value ranges from 1 to 36 and is obtained by taking the averaging scores from all four sections (english, math, reading, and science).|\n",
    "|state_sat_2017|object|SAT 2017|The state in which the SAT was taken in. Data reflected is from 2017.|\n",
    "|participation_sat_2017\t|float|SAT 2017|The SAT participation rate of eligible students in the state  in 2017. This is a percentage value saved as a float, with a maximum value  of 100, which means 100%.|\n",
    "|ebrw_sat_2017|float|SAT 2017|The average score across the state for the evidence-based reading and writing section of the SAT in 2017. This section is basically the SAT equivalent of the ACTs english and reading sections. This value ranges from 200 to 800.|\n",
    "|math_sat_2017|float|SAT 2017|The average score across the state for the math section of the SAT in 2017. This value ranges from 200 to 800.|\n",
    "|total_sat_2017|float|SAT 2017|The average overall score across the state for the SAT in 2017. This value ranges from 400 to 1600 and is the sum of the two sections in the SAT (english-based reading and writing, math).|\n",
    "|state_act_2018|object|ACT 2018|The state in which the ACT was taken in. Data reflected is from 2018.|\n",
    "|participation_act_2018\t|float|ACT 2018|The ACT participation rate of eligible students in the state  in 2018. This is a percentage value saved as a float, with a maximum value  of 100, which means 100%.|\n",
    "|english_act_2018|float|ACT 2018|The average score across the state for the english section of the ACT in 2018. This value ranges from 1 to 36.|\n",
    "|math_act_2018|float|ACT 2018|The average score across the state for the math section of the ACT in 2018. This value ranges from 1 to 36.|\n",
    "|reading_act_2018|float|ACT 2018|The average score across the state for the reading section of the ACT in 2018. This value ranges from 1 to 36.|\n",
    "|science_act_2018|float|ACT 2018|The average score across the state for the science section of the ACT in 2018. This value ranges from 1 to 36.|\n",
    "|composite_act_2018|float|ACT 2018|The average overall ACT score across the state in 2018. This value ranges from 1 to 36 and is obtained by taking the averaging scores from all four sections (english, math, reading, and science).|\n",
    "|state_sat_2018|object|SAT 2018|The state in which the SAT was taken in. Data reflected is from 2018.|\n",
    "|participation_sat_2018\t|float|SAT 2018|The SAT participation rate of eligible students in the state  in 2018. This is a percentage value saved as a float, with a maximum value  of 100, which means 100%.|\n",
    "|ebrw_sat_2018|float|SAT 2018|The average score across the state for the evidence-based reading and writing section of the SAT in 2018. This section is basically the SAT equivalent of the ACTs english and reading sections. This value ranges from 200 to 800.|\n",
    "|math_sat_2018|float|SAT 2018|The average score across the state for the math section of the SAT in 2018. This value ranges from 200 to 800.|\n",
    "|total_sat_2018|float|SAT 2018|The average overall score across the state for the SAT in 2018. This value ranges from 400 to 1600 and is the sum of the two sections in the SAT (english-based reading and writing, math).|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Drop unnecessary rows\n",
    "\n",
    "One of our dataframes contains an extra row. Identify and remove this from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first five rows of dataset 'pan_act_2017'\n",
    "pan_act_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing .drop to remove the first row of the 'pan_act_2017' dataset. \n",
    "# inplace is set to True so that we do not have to create a new variable.\n",
    "pan_act_2017.drop(0,axis = 0,inplace = True)\n",
    "pan_act_2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Merge Dataframes\n",
    "\n",
    "Join the 2017 ACT and SAT dataframes using the state in each dataframe as the key. Assign this to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies a outer merge to 'pan_sat_2017' and 'pan_act_2017' merging on the state.\n",
    "# This new dataframe is then saved to a new variable 'pan_merged_2017'\n",
    "pan_merged_2017 = pd.merge(pan_sat_2017,pan_act_2017, left_on='state_sat_2017', right_on='state_act_2017', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display first five rows of the 'pan_merged_2017' dataframe\n",
    "pan_merged_2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Save your cleaned, merged dataframe\n",
    "\n",
    "Use a relative path to save out your data as `combined_2017.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dataset 'pan_merged_2017' in relative path datasets/ as file 'combined_2017.csv'\n",
    "pan_merged_2017.to_csv('extradatasets/combined_2017.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to the 2018 ACT and SAT data are provided in the README. These data live in PDFs, and so you'll get to enjoy practicing some *manual* data collection. Save these data as a CSV in your `data` directory, and import, explore, and clean these data in the same way you did above. **Make sure you comment on your steps so it is clear *why* you are doing each process**.\n",
    "\n",
    "[1. Reading 2018 CSV Files](#1.-Reading-2018-CSV-Files): In order to manipulate the 2018 test data, we will have to first read it from a CSV File.\n",
    "\n",
    "[2. Viewing 2018 Dataframes](#2.-Viewing-2018-Dataframes): In order to know what needs to be cleaned-up, we will have to first view the 2018 test data.\n",
    "\n",
    "[3. Checking For Null Characters in 2018 Dataframes](#3.-Checking-For-Null-Characters-in-2018-Dataframes): First thing that we should always do when cleaning up data is to check for null characters.\n",
    "\n",
    "[4. Converting to Float](#4.-Converting-to-Float): We want to convert all numerical columns to float, so as to keep a consistent dataframe.\n",
    "\n",
    "[5. Column Name Cleanup](#5.-Column-Name-Cleanup): We want to clean up the column names to avoid any issues with spaces or symbols, and also to align with the 2017 dataframe.\n",
    "\n",
    "[6. Rearranging Columns to Match 2017 Dataframe](#6.-Rearranging-Columns-to-Match-2017-Dataframe): We want to rearrange the columns to match the 2017 dataframe.\n",
    "\n",
    "[7. Merging the 2018 Dataframes](#7.-Merging-the-2018-Dataframes): We want to merge both 2018 test dataframes to create one centralized dataframe.\n",
    "\n",
    "[8. Combine your 2017 and 2018 data into a single dataframe](#8.-Combine-your-2017-and-2018-data-into-a-single-dataframe): We want to merged both 2017 and 2018 dataframes to create one centralized dataframe.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Reading 2018 CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and assigning the datasets to appropriately named pandas dataframes\n",
    "pan_sat_2018 = pd.read_csv('../data/sat_2018.csv') # Test data obtained from GA git\n",
    "pan_act_2018 = pd.read_csv('../data/act_2018_updated.csv') # Test data obtained from GA git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Viewing 2018 Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 10 lines of panda dataframe 'pan_sat_2018'\n",
    "pan_sat_2018.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the first 10 lines of the SAT 2018 dataset, and nothing looks out of place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 10 lines of panda dataframe 'pan_act_2018'\n",
    "pan_act_2018.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the first 10 lines of the ACT 2018 dataset, and nothing looks out of place.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Checking For Null Characters in 2018 Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'pan_sat_2018' dataframe for null characters, and summing the number of null characters\n",
    "pan_sat_2018.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a sum of all the null characters in the SAT 2018 dataframe. There are no null characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'pan_act_2018' dataframe for null characters, and summing the number of null characters\n",
    "pan_act_2018.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a sum of all the null characters in the ACT 2018 dataframe. There are no null characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at dataframe information for the 'pan_sat_2018' dataframe\n",
    "pan_sat_2018.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the .info() of the SAT 2018 dataset. It appears that participation will have to be converted to a float. 'Evidence-based reading and writing', 'math', and 'total' will also need to be converted to a float for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at dataframe information for the 'pan_act_2018' dataframe\n",
    "pan_act_2018.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the .info() of the ACT 2018 dataset. It appears that 'percentage' of students tested may have to be converted to a float for consistency.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Converting to Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing the .str.replace function to replace the '%' character with '' for 'pan_sat_2018'\n",
    "pan_sat_2018['Participation'] = pan_sat_2018['Participation'].str.replace('%', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing datatype for cells column 'Participation' in dataframe 'pan_sat_2018' to float\n",
    "pan_sat_2018['Participation'] = pan_sat_2018['Participation'].apply(to_float)\n",
    "\n",
    "# Changing datatype for cells column 'Evidence-Based Reading and Writing' in dataframe 'pan_sat_2018' to float\n",
    "pan_sat_2018['Evidence-Based Reading and Writing'] = \\\n",
    "pan_sat_2018['Evidence-Based Reading and Writing'].apply(to_float)\n",
    "\n",
    "# Changing datatype for cells column 'Math' in dataframe 'pan_sat_2018' to float\n",
    "pan_sat_2018['Math'] = pan_sat_2018['Math'].apply(to_float)\n",
    "\n",
    "# Changing datatype for cells column 'Total' in dataframe 'pan_sat_2018' to float\n",
    "pan_sat_2018['Total'] = pan_sat_2018['Total'].apply(to_float)\n",
    "\n",
    "# Changing datatype for cells column 'Percentage of Students Tested' in dataframe 'pan_act_2018' to float\n",
    "pan_act_2018['Percentage of Students Tested'] = \\\n",
    "pan_act_2018['Percentage of Students Tested'].apply(to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then check for null characters, just in case the 'to_float' function encounters any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'pan_act_2018' dataframe for null characters, and summing the number of null characters\n",
    "pan_act_2018.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'pan_sat_2018' dataframe for null characters, and summing the number of null characters\n",
    "pan_sat_2018.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at dataframe information for the 'pan_act_2018' dataframe\n",
    "pan_act_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at dataframe information for the 'pan_sat_2018' dataframe\n",
    "pan_sat_2018.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frames have been succefully converted into proper types. The column names will need adjusting for consistency.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Column Name Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the word \"average \" from 2018 ACT column names\n",
    "pan_act_2018.columns = pan_act_2018.columns.str.replace('Average ', '').str.replace(' Score','')\n",
    "pan_act_2018.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names have been stripped of the prefix 'Average ' and suffix ' Score'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the 'Evidence-Based Reading And Writing' column name to 'EBRW' in the 'pan_sat_2018' dataset by utilizing .rename\n",
    "pan_sat_2018.rename(columns={\n",
    "    'Evidence-Based Reading and Writing' : 'EBRW',\n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the 'Percentage of Students Tested' column name to 'Participation' in the 'pan_act_2018' dataset by utilizing .rename\n",
    "pan_act_2018.rename(columns={\n",
    "    'Percentage of Students Tested' : 'Participation',\n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing capitalization and underscores from column names in datasets 'pan_act_2018' and 'pan_sat_2018'\n",
    "pan_act_2018.columns = pan_act_2018.columns.str.replace(' ','_').str.lower()\n",
    "pan_sat_2018.columns = pan_sat_2018.columns.str.replace(' ','_').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding test name and year to column names in datasets 'pan_sat_2018' and 'pan_act_2018'\n",
    "pan_sat_2018.columns = [column_names+'_sat_2018' for column_names in pan_sat_2018.columns]\n",
    "pan_act_2018.columns = [column_names+'_act_2018' for column_names in pan_act_2018.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 lines of panda dataframe 'pan_sat_2018'\n",
    "pan_sat_2018.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 lines of panda dataframe 'pan_act_2018'\n",
    "pan_act_2018.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names have now been properly cleaned up.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Rearranging Columns to Match 2017 Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging columns to match 2017 ACT dataframe\n",
    "pan_act_2018 = pan_act_2018[['state_act_2018', 'participation_act_2018', 'english_act_2018',\\\n",
    "       'math_act_2018', 'reading_act_2018', 'science_act_2018', 'composite_act_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 2 lines of panda dataframe 'pan_act_2018'\n",
    "pan_act_2018.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column order for the 2018 dataframes now matches the 2017 dataframes.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Merging the 2018 Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies a outer merge to 'pan_sat_2018' and 'pan_act_2018' merging on the state.\n",
    "# This new dataframe is then saved to a new variable 'pan_merged_2018'\n",
    "pan_merged_2018 = \\\n",
    "pd.merge(pan_sat_2018,pan_act_2018, left_on='state_sat_2018', right_on='state_act_2018', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 lines of panda dataframe 'pan_merged_2018'\n",
    "pan_merged_2018.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Combine your 2017 and 2018 data into a single dataframe\n",
    "Joining on state names should work, assuming you formatted all your state names identically. Make sure none of your columns (other than state) have identical names. Do yourself a favor and decide if you're encoding participation rates as floats or integers and standardize this across your datasets.\n",
    "\n",
    "Save the contents of this merged dataframe as `final.csv`.\n",
    "\n",
    "**Use this combined dataframe for the remainder of the project**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies a outer merge to 'pan_merged_2017' and 'pan_merged_2018' merging on the state.\n",
    "# This new dataframe is then saved to a new variable 'pan_merged_2018'\n",
    "pan_merged_final = \\\n",
    "pd.merge(pan_merged_2017,pan_merged_2018, left_on='state_sat_2017', right_on='state_sat_2018', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 lines of panda dataframe 'pan_merged_final'\n",
    "pan_merged_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dataset 'pan_merged_final' in relative path extradatasets/ as file 'final.csv'\n",
    "pan_merged_final.to_csv('extradatasets/final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for 2018 and 2017 have been successfully merged.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "* [Summary Statistics](#Summary-Statistics)\n",
    "* [Manually Calculate Standard Deviation](#Manually-calculate-standard-deviation)\n",
    "* [Investigate Trends in the Data](#Investigate-trends-in-the-data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "Transpose the output of pandas `describe` method to create a quick overview of each numeric feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the describe function on dataset 'pan_merged_final', \n",
    "# This dataframe is then rounded to two decimal places and a transpose via .T is performed\n",
    "round(pan_merged_final.describe(),2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually calculate standard deviation\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "- Write a function to calculate standard deviation using the formula above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring function to_sigma which calculates the standard deviation of a data series\n",
    "def to_sigma(dataseries):\n",
    "    n = dataseries.count()\n",
    "    mew = dataseries.mean()\n",
    "    summed = 0\n",
    "    for cells in dataseries:\n",
    "        summed += (cells - mew)**2\n",
    "    return(np.sqrt(summed/(n)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use a **dictionary comprehension** to apply your standard deviation function to each numeric column in the dataframe.  **No loops**  \n",
    "- Assign the output to variable `sd` as a dictionary where: \n",
    "    - Each column name is now a key \n",
    "    - That standard deviation of the column is the value \n",
    "     \n",
    "*Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing dictionary comprehension to apply standard deviation function to dataframe 'pan_merged_final'\n",
    "# for column names that do not contain the string 'state'\n",
    "sd = {column:to_sigma(pan_merged_final[column]) for column in pan_merged_final if 'state' not in column}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(pan_merged_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your manually calculated standard deviations match up with the output from pandas `describe`? What about numpy's `std` method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "It does not match up with pandas describe, but it does match up with numpy's std method.\n",
    "It does not line up with pandas describe, because the standard deviation formula given is for an entire population and not for a sample. Pandas calculation for standard deviation is for a sample, and thus has a n-1 in the denominator, as compared to just n.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate trends in the data\n",
    "Using sorting and/or masking (along with the `.head` method to not print our entire dataframe), consider the following questions:\n",
    "\n",
    "- Which states have the highest and lowest participation rates for the:\n",
    "    - [2017 SAT?](#2017-SAT-Participation-Rates)\n",
    "    - [2018 SAT?](#2018-SAT-Participation-Rates)\n",
    "    - [2017 ACT?](#2017-ACT-Participation-Rates)\n",
    "    - [2018 ACT?](#2018-ACT-Participation-Rates)\n",
    "- Which states have the highest and lowest mean total/composite scores for the:\n",
    "    - [2017 SAT?](#2017-SAT-Total-Score)\n",
    "    - [2018 SAT?](#2018-SAT-Total-Score)\n",
    "    - [2017 ACT?](#2017-ACT-Composite-Score)\n",
    "    - [2018 ACT?](#2018-ACT-Composite-Score)\n",
    "- Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "    - [States with 100% SAT Participation in 2017 and 2018](#2017-&-2018-SAT-100%-Participation)\n",
    "    - [States with 100% ACT Participation in 2017 and 2018](#2017-&-2018-ACT-100%-Participation)\n",
    "- Do any states show have >50% participation on *both* tests either year?\n",
    "    - [Greater than 50% participation on both tests](#Greater-than-50%-participation-on-both-tests)\n",
    "\n",
    "Based on what you've just observed, have you identified any states that you're especially interested in? Make a note of these and state *why* you think they're interesting. \n",
    "- [Observations: Total Scores, Participation Rates](#Observations:-Total-Scores,-Participation-Rates)\n",
    "\n",
    "**You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2017 SAT Participation Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing sort_values function to sort data frame by column. 'ascending' was set to False to obtain max values\n",
    "# Only columns 'state_sat_2017' and 'participation_sat_2017' were selected to be displayed\n",
    "# .head(5) was used to only display top five values\n",
    "pan_merged_final.sort_values('participation_sat_2017', ascending = False)\\\n",
    "[['state_sat_2017','participation_sat_2017']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing masking to select states with 2017 SAT participation rates that were lower than 3%\n",
    "# Only columns 'state_sat_2017' and 'participation_sat_2017' were selected to be displayed\n",
    "pan_merged_final[pan_merged_final['participation_sat_2017']<3][['state_sat_2017','participation_sat_2017']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participation for the 2017 SAT was the highest in states: District of Columbia(Washington DC), Michigan, Connecticut, Delaware, and New Hampshire. They each had a participation rate of 100%.\n",
    "\n",
    "The states that had the lowest participation in the 2017 SAT were: Iowa, Missisippi, and North Dakota. They each had a participation rate of 2%\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2018 SAT Participation Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing masking to select states with 2018 SAT participation rates that were higher than 99%\n",
    "# Only columns 'state_sat_2018' and 'participation_sat_2018' were selected to be displayed\n",
    "pan_merged_final[pan_merged_final['participation_sat_2018']>99][['state_sat_2018','participation_sat_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing sort_values function to sort data frame by column. 'ascending' was set to True to obtain min values\n",
    "# Only columns 'state_sat_2018' and 'participation_sat_2018' were selected to be displayed\n",
    "# .head(8) was used to only display top eight values\n",
    "pan_merged_final.sort_values('participation_sat_2018', ascending = True)[['state_sat_2018','participation_sat_2018']].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participation for the 2018 SAT was the highest in states: Colorado, Connecticut, Delaware, Idaho, and Michigan. They each had a participation rate of 100%.\n",
    "\n",
    "The states that had the lowest participation in the 2018 SAT were: North Dakota, Wyoming, South Dakota, Nebraska, Wisconsin, Mississippi, Iowa, and Utah.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2017 ACT Participation Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing masking to select states with 2017 ACT participation rates that were greater than 99%\n",
    "# Only columns 'state_act_2017' and 'participation_act_2017' were selected to be displayed\n",
    "pan_merged_final[pan_merged_final['participation_act_2017']>99][['state_act_2017','participation_act_2017']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing masking to select states with 2017 ACT participation rates that were less than 25%\n",
    "# Only columns 'state_act_2017' and 'participation_act_2017' were selected to be displayed\n",
    "pan_merged_final[pan_merged_final['participation_act_2017']<25][['state_act_2017','participation_act_2017']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participation for the 2017 ACT was the highest in states: Alabama, Arkansas, Colorado, Kentucky, Louisiana, Minnesota, Mississippi, Missouri, Montana, Nevada, North Carolina, Oklahoma, South Carolina, Tennessee, Utah, Wisconsin, and Wyoming. They each had a participation rate of 100%.\n",
    "\n",
    "The states that had the lowest participation in the 2017 ACT were: Delaware, Maine, New Hampshire, Pennsylvania, and Rhode Island.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2018 ACT Participation Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing masking to select states with 2018 ACT participation rates that were greater than 99%\n",
    "# Only columns 'state_act_2018' and 'participation_act_2018' were selected to be displayed\n",
    "pan_merged_final[pan_merged_final['participation_act_2018']>99][['state_act_2018','participation_act_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing masking to select states with 2018 ACT participation rates that were less than 20%\n",
    "# Only columns 'state_act_2018' and 'participation_act_2018' were selected to be displayed\n",
    "pan_merged_final[pan_merged_final['participation_act_2018']<20][['state_act_2018','participation_act_2018']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participation for the 2018 ACT was the highest in states: Alabama, Arkansas, Kentucky, Louisiana, Mississippi, Missouri, Montana, Nebraska, Nevada, North Carolina, Ohio, Oklahoma, South Carolina, Tennessee, Utah, Wisconsin, and Wyoming. They each had a participation rate of 100%.\n",
    "\n",
    "The states that had the lowest participation in the 2018 ACT were: Delaware, Maine, New Hampshire, and Rhode Island.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2017 SAT Total Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing sort_values function to sort data frame by column. 'ascending' was set to False to obtain max values\n",
    "# Only columns 'total_sat_2017' and 'state_sat_2017' were selected to be displayed\n",
    "# .head(5) was used to only display top five values\n",
    "pan_merged_final.sort_values('total_sat_2017', ascending = False)[['state_sat_2017', 'total_sat_2017']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing sort_values function to sort data frame by column. 'ascending' was set to True to obtain min values\n",
    "# Only columns 'total_sat_2017' and 'state_sat_2017' were selected to be displayed\n",
    "# .head(5) was used to only display top five values\n",
    "pan_merged_final.sort_values('total_sat_2017', ascending = True)[['state_sat_2017', 'total_sat_2017']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "States with the highest mean total SAT score in 2017 were: Minnesota, Wisconsin, Iowa, Missouri, and Kansas.\n",
    "    \n",
    "States with the lowest mean total SAT score in 2017 were: District of Columbia, Delaware, Idaho, Michigan, and Maine.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2018 SAT Total Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing sort_values function to sort data frame by column. 'ascending' was set to False to obtain max values\n",
    "# Only columns 'total_sat_2018' and 'state_sat_2018' were selected to be displayed\n",
    "# .head(5) was used to only display top five values\n",
    "pan_merged_final.sort_values('total_sat_2018', ascending = False)[['state_sat_2018', 'total_sat_2018']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing sort_values function to sort data frame by column. 'ascending' was set to True to obtain min values\n",
    "# Only columns 'total_sat_2018' and 'state_sat_2018' were selected to be displayed\n",
    "# .head(5) was used to only display top five values\n",
    "pan_merged_final.sort_values('total_sat_2018', ascending = True)[['state_sat_2018', 'total_sat_2018']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "States with the highest mean total SAT score in 2018 were: Minnesota, Wisconsin, North Dakota, Iowa, and Kansas.\n",
    "\n",
    "States with the lowest mean total SAT score in 2018 were: District of Columbia, Delaware, West Virginia, Idaho, and Utah.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2017 ACT Composite Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing sort_values function to sort data frame by column. 'ascending' was set to False to obtain max values\n",
    "# Only columns 'total_act_2017' and 'composite_act_2017' were selected to be displayed\n",
    "# .head(5) was used to only display top five values\n",
    "pan_merged_final.sort_values('composite_act_2017', ascending = False)[['state_act_2017', 'composite_act_2017']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing sort_values function to sort data frame by column. 'ascending' was set to True to obtain max values\n",
    "# Only columns 'total_act_2017' and 'composite_act_2017' were selected to be displayed\n",
    "# .head(5) was used to only display top five values\n",
    "pan_merged_final.sort_values('composite_act_2017', ascending = True)[['state_act_2017', 'composite_act_2017']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "States with the highest mean composite ACT score in 2017 were: New Hampshire, Massachusetts, Connecticut, Maine, and District of Columbia.\n",
    "\n",
    "States with the lowest mean composited ACT score in 2017 were: Nevada, Mississippi, South Carolina, Hawaii, and North Carolina.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2018 ACT Composite Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing sort_values function to sort data frame by column. 'ascending' was set to False to obtain max values\n",
    "# Only columns 'total_act_2018' and 'composite_act_2018' were selected to be displayed\n",
    "# .head(5) was used to only display top five values\n",
    "pan_merged_final.sort_values('composite_act_2018', ascending = False)[['state_act_2018', 'composite_act_2018']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing sort_values function to sort data frame by column. 'ascending' was set to True to obtain min values\n",
    "# Only columns 'total_act_2018' and 'composite_act_2018' were selected to be displayed\n",
    "# .head(5) was used to only display top five values\n",
    "pan_merged_final.sort_values('composite_act_2018', ascending = True)[['state_act_2018', 'composite_act_2018']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "States with the highest mean composite ACT score in 2018 were: Connecticut, Massachusetts, New Hampshire, New York, and Michigan.\n",
    "\n",
    "States with the lowest mean composited ACT score in 2018 were: Nevada, South Carolina, Mississippi, Hawaii, and Alabama.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2017 & 2018 SAT 100% Participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize masking to display rows at which 'participation_sat_2017' and 'participation_sat_2018' is equal to 100\n",
    "# Only the state and participation rate collumns were selected to be displayed\n",
    "pan_merged_final[(pan_merged_final['participation_sat_2017']==100) & \\\n",
    "                 (pan_merged_final['participation_sat_2018']==100)]\\\n",
    "[['state_sat_2017','participation_sat_2017','participation_sat_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values at which 'participation_sat_2017' is equal to 100\n",
    "pan_merged_final[pan_merged_final['participation_sat_2017']==100]['state_sat_2017'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values at which 'participation_sat_2017' and 'participation_sat_2018' is equal to 100\n",
    "pan_merged_final[(pan_merged_final['participation_sat_2017']==100) & \\\n",
    "                 (pan_merged_final['participation_sat_2018']==100)]['state_sat_2017'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 4 states that had a 100% participation in the 2017 SAT, 3 of them also achieved a 100% participation in the 2018 SAT. These states are: Connecticut, Delaware, and Michigan.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2017 & 2018 ACT 100% Participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize masking to display rows at which 'participation_act_2017' and 'participation_act_2018' is equal to 100\n",
    "# Only the state and participation rate collumns were selected to be displayed\n",
    "pan_merged_final[(pan_merged_final['participation_act_2017']==100) & \\\n",
    "                 (pan_merged_final['participation_act_2018']==100)]\\\n",
    "[['state_act_2017', 'participation_act_2017', 'participation_act_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values at which 'participation_act_2017' is equal to 100\n",
    "pan_merged_final[pan_merged_final['participation_act_2017']==100]['state_sat_2017'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values at which 'participation_act_2017' and 'participation_act_2018' is equal to 100\n",
    "pan_merged_final[(pan_merged_final['participation_act_2017']==100) & \\\n",
    "                 (pan_merged_final['participation_act_2018']==100)]\\\n",
    "['state_sat_2017'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 17 states that had a 100% participation in the 2017 ACT, 15 of them also achieved a 100% participation in the 2018 ACT. These states are: Alabama, Arkansas, Kentucky, Louisiana, Mississippi, Missouri, Montana, Nevada, North Carolina, Oklahoma\n",
    ", South Carolina, Tennessee, Utah, Wisconsin, and Wyoming.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Greater than 50% participation on both tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing masking to display states that have a participation rate in 2017 that is higher than 50% in both SAT and ACT\n",
    "pan_merged_final[(pan_merged_final['participation_act_2017']>50) & \\\n",
    "                 (pan_merged_final['participation_sat_2017']>50)]\\\n",
    "[['state_sat_2017', 'participation_sat_2017', 'participation_act_2017']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing masking to display states that have a participation rate in 2018 that is higher than 50% in both SAT and ACT\n",
    "pan_merged_final[(pan_merged_final['participation_act_2018']>50) & \\\n",
    "                 (pan_merged_final['participation_sat_2018']>50)]\\\n",
    "[['state_sat_2018', 'participation_sat_2018', 'participation_act_2018']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Florida, Georgia, and Hawaii all had participation rates in 2017 and 2018 that were greater than 50% for both the SAT and ACT.\n",
    "\n",
    "North Carolina and South Carolina both had participation rates in 2018 that were greater than 50% for both the SAT and ACT.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations: Total Scores, Participation Rates\n",
    "\n",
    "Based on observations, \n",
    "* SAT participation rates *may have a* negative correlation with ACT participation rates\n",
    "* SAT participation rates *may have a* negative correlation with SAT total scores\n",
    "* ACT participation rates *may have a* negative correlation with ACT composite scores\n",
    "\n",
    "The states I am especially interested in are: Florida, Georgia, Hawaii, Utah and Colorado. I am interested in these states for the following reasons:\n",
    "* Florida, Georgia, Hawaii - Had high participation in both SAT and ACT for both 2017 and 2018\n",
    "    * Perhaps there could be an underlying policy or reason for high participation in both tests.\n",
    "* Colorado - Had high ACT participation rates in 2017, but not in 2018. Colorado also had high SAT participation in 2018\n",
    "    * This was not observed in any other state\n",
    "* Utah - Has low SAT participation 2018, and also had low SAT scores in 2018\n",
    "    * This was also not observed in any other state\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers.\n",
    "\n",
    "Some recommendations on plotting:\n",
    "- Plots have titles\n",
    "- Plots have axis labels\n",
    "- Plots have appropriate tick labels\n",
    "- All text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Plots are interpreted to aid understanding\n",
    "\n",
    "There is such a thing as too many plots, and there are a *lot* of bad plots. You might make some! (But hopefully not with the guided prompts below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features\n",
    "\n",
    "Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "\n",
    "*example*:\n",
    "```python\n",
    "sns.heatmap(df.corr())\n",
    "```\n",
    "\n",
    "Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing seaborn to plot heatmap of all variables for SAT 2017, SAT 2018, ACT 2017, and ACT 2018\n",
    "fig, ax = plt.subplots(figsize = (15,8)) # Setting the figsize to 15, 8\n",
    "heatmat = np.triu(pan_merged_final.corr()) # Creating the mask using upper triangle numpy array\n",
    "\n",
    "# Plotting the heatmap via heatmap function\n",
    "sns.heatmap(pan_merged_final.corr(), annot = True, fmt='.2g', mask=heatmat)\\\n",
    ".set_title('Heatmap - All Variables - SAT 2017, SAT 2018, ACT 2017, ACT 2018', fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing seaborn to plot heatmap of participation, total, and composite in SAT 2018, ACT 2017, and ACT 2018\n",
    "fig, ax = plt.subplots(figsize = (15,8)) # Setting the figsize to 15, 8\n",
    "\n",
    "# Creating the mask using upper triangle numpy array\n",
    "# Line continuation character has been implemented to improve readability\n",
    "heatmat = np.triu(pan_merged_final[['participation_sat_2017', \\\n",
    "                                    'participation_sat_2018', \\\n",
    "                                    'participation_act_2017', \\\n",
    "                                    'participation_act_2018', \\\n",
    "                                    'total_sat_2017', \\\n",
    "                                    'total_sat_2018', \\\n",
    "                                    'composite_act_2017', \\\n",
    "                                    'composite_act_2018']].corr())\n",
    "\n",
    "# Plotting the heatmap via heatmap function\n",
    "# Line continuation character has been implemented to improve readability\n",
    "sns.heatmap(pan_merged_final[['participation_sat_2017', \\\n",
    "                              'participation_sat_2018', \\\n",
    "                              'participation_act_2017', \\\n",
    "                              'participation_act_2018', \\\n",
    "                              'total_sat_2017', \\\n",
    "                              'total_sat_2018', \\\n",
    "                              'composite_act_2017', \\\n",
    "                              'composite_act_2018']].corr(), \\\n",
    "            annot = True, fmt='.2g', mask=heatmat)\\\n",
    ".set_title('Heatmap - Participation, Total, and Composite - SAT 2017, SAT 2018, ACT 2017, ACT 2018', fontsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a custom function to subplot histograms\n",
    "\n",
    "We have data for two tests for two years. We only have composite (and not subtest scores) for the 2018 ACT. We should write a function that will take the names of 2+ columns and subplot histograms. While you can use pandas plotting or Seaborn here, matplotlib gives you greater control over all aspects of your plots.\n",
    "\n",
    "[Helpful Link for Plotting Multiple Figures](https://matplotlib.org/users/pyplot_tutorial.html#working-with-multiple-figures-and-axes)\n",
    "\n",
    "Here's some starter code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that accepts the names of 2+ columns and plots histograms into subplots.\n",
    "def subplot_histograms(list_of_columns, dataframe = pan_merged_final): # Setting the default dataframe to be 'pan_merged_final'\n",
    "    \"\"\"Function plots histograms into subplots based on input:\n",
    "    list_of_columns, dataframe = pan_merged_final\"\"\"\n",
    "    temp_list = [] # Creating a temporary list to help us remove unwanted 'state' columns in the pan_merged_final dataframe\n",
    "    for name in list_of_columns: # for loop iterates for every column in 'list_of_columns'\n",
    "        if 'state' in name: # Conditional if statement will pass if the string 'state' is in the column name\n",
    "            pass\n",
    "        else: # If 'state' is not in the column name, column name will be appended into 'temp_list'\n",
    "            temp_list.append(name)\n",
    "    list_of_columns = temp_list # Setting 'list_of_columns' to 'temp_list'\n",
    "    nrows = int(np.ceil(len(list_of_columns)/2)) # Counting the number of rows required\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2, figsize = (15,10*nrows/2)) # figsize is scaled based on number of rows\n",
    "    ax = ax.ravel() # Ravel turns a matrix into a vector, which is easier to iterate\n",
    "    for index, column in enumerate(list_of_columns): # Gives us an index value to get into all our lists\n",
    "        ax[index].grid() # Turns grid on for every iteration (every subplot)\n",
    "        ax[index].grid(which='major', alpha=0.4) # Sets grid opacity\n",
    "        ax[index].set_yticks(np.arange(0,52,1)) #\n",
    "        ax[index].hist(dataframe[column], bins = 15) # Histogram plot in subplot of index i\n",
    "        \n",
    "        # Setting title that will generate based on column name\n",
    "        ax[index].set_title('Histogram - ' + column.replace('_', ' ').split()[0].title() + ' ' \\\n",
    "                        + column.replace('_', ' ').split()[1].upper() + ' ' \\\n",
    "                        + column.replace('_', ' ').split()[2])\n",
    "        \n",
    "        # Setting y label to be 'number of US states'\n",
    "        ax[index].set_ylabel('Number of US States (n = ' + str(len(dataframe.index)) +')')\n",
    "        \n",
    "        # If statement controls x label, as participation rate requires a different format\n",
    "        if 'participation' in column:\n",
    "            ax[index].set_xlabel('Participation Rate (%)')\n",
    "        else:\n",
    "            ax[index].set_xlabel('Mean ' + column.replace('_', ' ').split()[0].title() + ' '\\\n",
    "                             + 'Score')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret histograms \n",
    "For each of the following:\n",
    "- [Participation rates for SAT & ACT](#SAT-&-ACT-Participation-Rate-Histograms)\n",
    "- [Math scores for SAT & ACT](#SAT-&-ACT-Mean-Math-Score-Histograms)\n",
    "- [Reading/verbal scores for SAT & ACT](#SAT-&-ACT-Mean-Reading/Verbal-Score-Histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SAT & ACT Participation Rate Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call to plot histogram for columns in 'pan_merged_final' that have column names containing the string 'participation'\n",
    "subplot_histograms([column for column in pan_merged_final if 'participation' in column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "\n",
    "\n",
    "For the SAT,\n",
    "* The highest peak resides in participation rates of between 0% and 10% for both years.\n",
    "\n",
    "For the ACT,\n",
    "* The highest peak resides in participation rates between 90% and 100% for both years.\n",
    "\n",
    "For both tests,\n",
    "* For overall participation, it appears that there is a random distribution as it follows no apparent pattern. \n",
    "* When isolating the tests and comparing year on year, the participation rates appear to have high correlation.\n",
    "* It may be worth looking at the number of states in which SAT or ACT is mandatory to see if there is a reason for this trend.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SAT & ACT Mean Math Score Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call to plot histogram for columns in 'pan_merged_final' that have column names containing the string 'math'\n",
    "subplot_histograms([column for column in pan_merged_final if 'math' in column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "For the SAT,\n",
    "* The highest peak occurs between a math score of 500 and 550.\n",
    "\n",
    "For the ACT,\n",
    "* The highest peak occurs between a math score of 19 and 20.\n",
    "\n",
    "For both tests,\n",
    "* We observe what resembles a normal distribution on the left side of the each histogram. We do see some outliers on the right side of the plot.\n",
    "* All four datasets share a similar shape, however the scale of the scores are different between SAT and ACT.\n",
    "* When isolating the tests and comparing year on year, the math scores appear to have high correlation.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SAT & ACT Mean Reading/Verbal Score Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call to plot histogram for columns in 'pan_merged_final' that have column names containing \n",
    "# any of the following strings: 'reading', 'english', 'ebrw'\n",
    "subplot_histograms([column for column in pan_merged_final\\\n",
    "                    if ('reading' in column) | ('english' in column)| ('ebrw' in column)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "For the SAT, \n",
    "\n",
    "* The highest peak occurs between a score of 520 and 560.\n",
    "\n",
    "For the ACT, \n",
    "\n",
    "* The highest peak occurs between a score of 20 and 22 with the exception of English ACT scores in 2018. \n",
    "* English ACT scores in 2018 had its highest peak at around a score of 24. However, it is hard to determine if this is significant as the difference between the highest peak and second highest peak is only 1 state.\n",
    "\n",
    "For both tests, \n",
    "\n",
    "* We observe what resembles a normal distribution on the left side of the plot. We do see some outliers on the right side of the plot.\n",
    "* All six datasets generally share a similar shape, however the scale of the scores are different between SAT and ACT.\n",
    "* When isolating the tests and comparing year on year, the scores generally appear to have high correlation.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret scatter plots\n",
    "\n",
    "For each of the following:\n",
    "- [SAT vs. ACT math scores for 2017](#Scatter-Plot---SAT-vs.-ACT-math-scores-for-2017)\n",
    "- [SAT vs. ACT verbal/reading scores for 2017](#Scatter-Plot---SAT-vs.-ACT-verbal/reading-scores-for-2017)\n",
    "- [SAT vs. ACT total/composite scores for 2017](#Scatter-Plot---SAT-vs.-ACT-total/composite-scores-for-2017)\n",
    "- [Total scores for SAT 2017 vs. 2018](#Scatter-Plot---Total-scores-for-SAT-2017-vs.-2018)\n",
    "- [Composite scores for ACT 2017 vs. 2018](#Scatter-Plot---Composite-scores-for-ACT-2017-vs.-2018)\n",
    "\n",
    "Plot the two variables against each other using matplotlib or Seaborn\n",
    "\n",
    "Your plots should show:\n",
    "- Two clearly labeled axes\n",
    "- A proper title\n",
    "- Using colors and symbols that are clear and unmistakable\n",
    "\n",
    "**Feel free to write a custom function, and subplot if you'd like.** Functions save both time and space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function declaration for 'scatter_plot' function that accepts a list of column names, plot title, x-axis label,\n",
    "# y-axis label, and dataframe\n",
    "# This function will be used to plot scatter plots on any two given numeric data series\n",
    "def scatter_plot(list_of_columns, title, xlabel, ylabel, dataframe = pan_merged_final):\n",
    "    \"\"\"This function is used to plot a scatter plot and accepts inputs: \n",
    "    (list_of_columns, title, xlabel, ylabel, dataframe = pan_merged_final) \"\"\"\n",
    "    fig, ax = plt.subplots(figsize = (15,8)) # Specifying figsize\n",
    "    plt.xticks(fontsize=14) # Setting fontsize of x axis legends\n",
    "    plt.yticks(fontsize=14) # Setting fontsize of y axis legends\n",
    "    plt.grid() # Applying grid to plot\n",
    "    plt.grid(which='major', alpha=0.4) # Sets grid opacity\n",
    "    ax.set_xlabel(xlabel, fontsize = 17) # Applying x-axis label to plot\n",
    "    ax.set_ylabel(ylabel, fontsize = 17) # Applying y-axis label to plot\n",
    "    ax.set_title(title, fontsize = 22) # Applying title to plot\n",
    "\n",
    "    plt.scatter(dataframe[list_of_columns[0]],dataframe[list_of_columns[1]], c='crimson', s = 120) # Plotting the scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatter Plot - SAT vs. ACT math scores for 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling 'scatter_plot' function to plot a scatter plot of 'math_sat_2017' vs 'math_act_2017'\n",
    "scatter_plot(['math_sat_2017','math_act_2017'], \\\n",
    "             \"Scatter Plot of State ACT and SAT Mean Math Scores in 2017\", \\\n",
    "             \"Mean SAT Math Score\", \"Mean ACT Math Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "For the Scatter Plot of State ACT and SAT Mean Math Scores in 2017, there appears to be little to no significant clustering, nor is there any observable trend.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatter Plot - SAT vs. ACT verbal/reading scores for 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving a copy of 'pan_merged_final' dataframe in 'act_verbal_df'\n",
    "act_verbal_df = pan_merged_final \n",
    "\n",
    "# Summing the two verbal components in the ACT test\n",
    "act_verbal_df['verbal_act_2017'] = \\\n",
    "act_verbal_df['english_act_2017'] + act_verbal_df['reading_act_2017']\n",
    "\n",
    "# Calling 'scatter_plot' function to plot a scatter plot of verbal test scores between SAT and ACT in 2017'\n",
    "scatter_plot(['ebrw_sat_2017','verbal_act_2017'], \\\n",
    "             \"Scatter Plot of State ACT and SAT Mean Verbal Scores in 2017\", \\\n",
    "             \"Mean SAT English-Based Reading and Writing Score\", \\\n",
    "             \"Mean ACT Verbal Score (English and Reading Sum)\", \\\n",
    "             dataframe = act_verbal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "For the Scatter Plot of State ACT and SAT Mean Verbal Scores in 2017, there appears to be little to no significant clustering, nor is there any observable trend.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatter Plot - SAT vs. ACT total/composite scores for 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling 'scatter_plot' function to plot a scatter plot of 'total_sat_2017' vs 'composite_act_2017'\n",
    "scatter_plot(['total_sat_2017','composite_act_2017'], \\\n",
    "             \"Scatter Plot of State ACT and SAT Composite/Total Scores in 2017\", \\\n",
    "             \"Mean SAT Total Score\", \"Mean ACT Composite Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "For the Scatter Plot of State ACT and SAT Composite/Total Scores in 2017, there appears to be little to no significant clustering, nor is there any observable trend.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatter Plot - Total scores for SAT 2017 vs. 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling 'scatter_plot' function to plot a scatter plot of 'total_sat_2017' vs 'total_sat_2018'\n",
    "scatter_plot(['total_sat_2017','total_sat_2018'], \\\n",
    "             \"Scatter Plot of SAT Total Scores in 2017 and 2018\", \\\n",
    "             \"Mean Total Score 2017\", \"Mean Total Score 2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "For the scatter plot of SAT Total Scores in 2017 and 2018, there is a strong, positive, linear association between the two variables with a few potential outliers.\n",
    "\n",
    "This means that any given state is likely to have similar total scores for the SAT in 2017 and 2018.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatter Plot - Composite scores for ACT 2017 vs. 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling 'scatter_plot' function to plot a scatter plot of 'composite_act_2017' vs 'composite_act_2018'\n",
    "scatter_plot(['composite_act_2017','composite_act_2018'], \\\n",
    "             \"Scatter Plot of ACT Composite Scores in 2017 and 2018\", \\\n",
    "             \"Mean Composite Score 2017\", \"Mean Composite Score 2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "For the scatter plot of ACT Composite Scores in 2017 and 2018, there is a strong, positive, linear association between the two variables with a few potential outliers.\n",
    "\n",
    "This means that any given state is likely to have similar composite scores for the ACT in 2017 and 2018.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret boxplots\n",
    "\n",
    "For each numeric variable in the dataframe create a boxplot using Seaborn. Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "\n",
    "Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "\n",
    "Each boxplot should:\n",
    "- Only include variables of a similar scale\n",
    "- Have clear labels for each variable\n",
    "- Have appropriate titles and labels\n",
    "\n",
    "List of Boxplots:\n",
    "- [Box Plot - SAT and ACT Participation Rates](#Box-Plot---SAT-and-ACT-Participation-Rates)\n",
    "- [Box Plot - SAT and ACT Math and EBRW Mean Score](#Box-Plot----SAT-and-ACT-Math-and-EBRW-Mean-Score)\n",
    "- [Box Plot - SAT Total Mean Score](#Box-Plot----SAT-Total-Mean-Score)\n",
    "- [Box Plot - ACT Verbal Mean Score](#Box-Plot----ACT-Verbal-Mean-Score)\n",
    "- [Box Plot - ACT Math, Science, Composite Score](#Box-Plot---ACT-Math,-Science,-Composite-Score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaration for 'box_plotty' function which plots a box plots based on a number of parameters:\n",
    "# 'column_names' - names of the columns to plot, 'xtick_labels' - Names of x-axis legends,\n",
    "# 'ylabel' - y-axis title, 'title' - plot title\n",
    "def box_plotty(column_names, xtick_labels, ylabel, title, fndf = pan_merged_final):\n",
    "    \"\"\"This functioin plots a number of boxplots on the same plot based on the following inputs:\n",
    "    column_names, xtick_labels, ylabel, title, fndf = pan_merged_final\"\"\"\n",
    "    fig, ax = plt.subplots(figsize = (15,8)) # Setting the figure size\n",
    "    df = pd.DataFrame(data = fndf, columns = column_names) # Setting the column names\n",
    "    plt.xticks(fontsize=15) # Setting the x-axis legend font size\n",
    "    plt.yticks(fontsize=18) # Setting the y-axis legend font size\n",
    "    #plt.grid()\n",
    "    plotty = sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(df), showfliers=True) # Plotting the box plot\n",
    "    sns.swarmplot(x=\"variable\", y=\"value\", data=pd.melt(df), color=\"gold\", edgecolor = 'black', size = 8) # Adding a swarm plot\n",
    "    plotty.axes.set_title(title,fontsize=25) # Adding a plot title\n",
    "    plotty.set_xlabel(\"\",fontsize=20) # Removing the x-axis label\n",
    "    plotty.set_ylabel(ylabel,fontsize=20) # Changing the y-axis label\n",
    "    plotty.set(xticklabels=xtick_labels); # Changing the x-axis legends\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box Plot - SAT and ACT Participation Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the 'box_plotty' function to plot box plots of:\n",
    "# 'participation_sat_2017', 'participation_sat_2018', 'participation_act_2017', and 'participation_act_2018'\n",
    "box_plotty(['participation_sat_2017','participation_sat_2018','participation_act_2017','participation_act_2018'],\\\n",
    "          ['2017 SAT Participation', '2018 SAT Participation', '2017 ACT Participation', '2018 ACT Participation'],\n",
    "          \"State Participation Rate (%)\",\n",
    "          \"Box Plot - Participation Rate - SAT and ACT in 2017 and 2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "A swarmplot has been superimposed on the boxplot for a better idea of the distribution.\n",
    "\n",
    "\n",
    "For SAT participation rates in 2017 and 2018, \n",
    "* We see that there is some clustering at 40% to 80%. \n",
    "* There is also a sugnificant number of points that lie outside of the IQR, especially on the lower side of the IQR. \n",
    "* It is noted that no points lie outside of the max (Q3 + 1.5*IQR) and min (Q1 - 1.5*IQR) boundaries. \n",
    "* For both years Q1 sits between 0% and 10%, Q2 sits between 35% to 55%, and Q3 sits between 60% and 80%.\n",
    "* Year on year comparison shows a rather similar distribution.\n",
    "\n",
    "For ACT participation rates in 2017 and 2018, \n",
    "* We see that there is significant clustering at Q1, and Q3. There is also some slight clustering at Q2.\n",
    "* There is also a number of points that lie outside the bottom range of the IQR.\n",
    "* It is noted that no points lie outside of the max (Q3 + 1.5*IQR) and min (Q1 - 1.5*IQR) boundaries. \n",
    "* For both years Q1 sits between 20% and 30%, Q2 sits between 60% to 80%, and Q3 sits at around 100%.\n",
    "* Year on year comparison shows a very similar distribution.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box Plot -  SAT and ACT Math and EBRW Mean Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calling the 'box_plotty' function to plot box plots of:\n",
    "# 'math_sat_2017', 'math_sat_2018', 'math_act_2017', and 'math_act_2018'\n",
    "box_plotty(['math_sat_2017','math_sat_2018','ebrw_sat_2017','ebrw_sat_2018'],\\\n",
    "          ['2017 SAT Math', '2018 SAT Math', '2017 SAT EBRW', '2018 SAT EBRW'],\n",
    "          \"State Mean Score\",\n",
    "          \"Box Plot - SAT Math and EBRW Mean Score in 2017 and 2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "A swarmplot has been superimposed on the boxplot for a better idea of the distribution.\n",
    "\n",
    "\n",
    "For SAT Mean Math Scores in 2017 and 2018, \n",
    "* We see that there is significant clustering between Q1 and Q2\n",
    "* There is also a sugnificant number of points that lie outside of the IQR on both sides.\n",
    "* It is noted that no points lie outside of the max (Q3 + 1.5*IQR) and min (Q1 - 1.5*IQR) boundaries. \n",
    "* For both years Q1 lies close to a score of 525, Q2 lies close to a score of 550, and Q3 lies close to a score of 600.\n",
    "* Year on year comparison shows a very similar distribution.\n",
    "\n",
    "For SAT Mean EBRW Scores in 2017 and 2018, \n",
    "* We see that there is significant clustering between Q1 and Q2, with some clusters occuring outside the IQR.\n",
    "* It is noted that no points lie outside of the max (Q3 + 1.5*IQR) and min (Q1 - 1.5*IQR) boundaries. \n",
    "* For both years Q1 lies close to a score of 525, Q2 lies close to a score of 550, and Q3 lies between a score of 600 and 625.\n",
    "* Year on year comparison shows a very similar distribution.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box Plot -  SAT Total Mean Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the 'box_plotty' function to plot box plots of: 'total_sat_2017' and 'total_sat_2018'\n",
    "box_plotty(['total_sat_2017','total_sat_2018'],\\\n",
    "          ['2017 SAT Total', '2018 SAT Total'],\n",
    "          \"State Mean Score\",\n",
    "          \"Box Plot - SAT Total Mean Score in 2017 and 2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "A swarmplot has been superimposed on the boxplot for a better idea of the distribution.\n",
    "\n",
    "\n",
    "For SAT Mean Total Scores in 2017 and 2018, \n",
    "* We see that there is significant clustering between Q1 and Q2\n",
    "* There is also a sugnificant number of points that lie outside of the IQR on both sides.\n",
    "* It is noted that no points lie outside of the max (Q3 + 1.5*IQR) and min (Q1 - 1.5*IQR) boundaries. \n",
    "* For both years Q1 lies close to a score of 1050, Q2 lies close to a score of 1100, and Q3 lies close to a score of 1200.\n",
    "* Year on year comparison shows a very similar distribution.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box Plot -  ACT Verbal Mean Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the 'box_plotty' function to plot box plots of:\n",
    "# 'reading_act_2017', 'reading_act_2018', 'english_act_2017', and 'english_act_2018'\n",
    "box_plotty(['reading_act_2017','reading_act_2018',\\\n",
    "            'english_act_2017','english_act_2018'],\\\n",
    "          ['2017 ACT Reading','2018 ACT Reading',\\\n",
    "            '2017 ACT English','2018 ACT English'],\n",
    "          \"State Mean Score\",\n",
    "          \"Box Plot - ACT Verbal Mean Score in 2017 and 2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "A swarmplot has been superimposed on the boxplot for a better idea of the distribution.\n",
    "\n",
    "\n",
    "For ACT Mean Reading Scores in 2017 and 2018, \n",
    "* We see that there is significant clustering around Q1, and some clustering just above Q3.\n",
    "* There is also a sugnificant number of points that lie outside of the IQR on both sides.\n",
    "* It is noted that no points lie outside of the max (Q3 + 1.5*IQR) and min (Q1 - 1.5*IQR) boundaries. \n",
    "* For both years Q1 lies close to a score of 20.5, Q2 lies close to a score of 22, and Q3 lies close to a score of 24.\n",
    "* Year on year comparison shows a very similar distribution.\n",
    "\n",
    "For ACT Mean English Scores in 2017 and 2018, \n",
    "* We see that there is significant clustering around Q1, with some clusters occuring just above Q3.\n",
    "* It is noted that no points lie outside of the max (Q3 + 1.5*IQR) and min (Q1 - 1.5*IQR) boundaries. \n",
    "* For both years Q1 lies close to a score of 19, Q2 lies close to a score of 20.5, and Q3 lies close to a score of 23.5.\n",
    "* Year on year comparison shows a very similar distribution.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box Plot - ACT Math, Science, Composite Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the 'box_plotty' function to plot box plots of:\n",
    "# 'math_act_2017', 'math_act_2018', 'science_act_2017', 'science_act_2018', 'composite_act_2017', and 'composite_act_2018'\n",
    "box_plotty(['math_act_2017','math_act_2018',\\\n",
    "            'science_act_2017', 'science_act_2018',\\\n",
    "            'composite_act_2017','composite_act_2018'],\\\n",
    "          ['2017 Math','2018 Math ',\\\n",
    "           '2017 Science', '2018 Science',\\\n",
    "            '2017 Composite','2018 Composite'],\n",
    "          \"State Mean Score\",\n",
    "          \"Box Plot - ACT Math, Science, Composite Scores in 2017 and 2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "A swarmplot has been superimposed on the boxplot for a better idea of the distribution.\n",
    "\n",
    "\n",
    "For ACT Mean Math Scores in 2017 and 2018, \n",
    "* We see that there is some minor clustering around Q1 and Q3.\n",
    "* There is also a sugnificant number of points that lie outside of the IQR on both sides.\n",
    "* It is noted that no points lie outside of the max (Q3 + 1.5*IQR) and min (Q1 - 1.5*IQR) boundaries. \n",
    "* For both years Q1 lies close to a score of 19.5, Q2 lies close to a score of 21, and Q3 lies close to a score of 23.\n",
    "* Year on year comparison shows a very similar distribution.\n",
    "\n",
    "For ACT Mean Science Scores in 2017 and 2018, \n",
    "* We see that there is significant between Q1 and Q2, and some minor clustering just above Q3.\n",
    "* It is noted that no points lie outside of the max (Q3 + 1.5*IQR) and min (Q1 - 1.5*IQR) boundaries. \n",
    "* For both years Q1 lies close to a score of 20, Q2 lies close to a score of 21, and Q3 lies close to a score of 23.\n",
    "* Year on year comparison shows a very similar distribution.\n",
    "\n",
    "For ACT Mean Composite Scores in 2017 and 2018, \n",
    "* We see that there is significant clustering above Q1, Q2, and Q3.\n",
    "* It is noted that no points lie outside of the max (Q3 + 1.5*IQR) and min (Q1 - 1.5*IQR) boundaries. \n",
    "* For both years Q1 lies close to a score of 20, Q2 lies close to a score of 21.5, and Q3 lies close to a score of 23.5.\n",
    "* Year on year comparison shows a very similar distribution.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feel free to do additional plots below\n",
    "*(do research and choose your own chart types & variables)*\n",
    "\n",
    "Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call to plot histogram for columns in 'pan_merged_final' that have column names containing the string 'total'\n",
    "subplot_histograms([column for column in pan_merged_final if 'total' in column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional): Using Tableau, create a choropleth map for each variable using a map of the US. \n",
    "\n",
    "Save this plot as an image file in an images directory, provide a relative path, and insert the image into notebook in markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing Distributions\n",
    "\n",
    "Above, we used pandas `describe` to provide quick summary statistics of our numeric columns. We also demonstrated many visual relationships.\n",
    "\n",
    "As data scientists, having a complete understanding of data is imperative prior to modeling.\n",
    "\n",
    "While we will continue to build our analytic tools, we know that measures of *central tendency*, *spread*, and *shape/skewness* provide a quick summary of distributions.\n",
    "\n",
    "For each variable in your data, summarize the underlying distributions (in words & statistics)\n",
    " - Be thorough in your verbal description of these distributions.\n",
    " - Be sure to back up these summaries with statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "|Feature|Count|Mean|Std Dev|Min|Q1(25%)|Q2(50%)|Q3(75%)|Max|Absolute Range|Distribution|Description|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "state_sat_2017|51.0|N/A|N/A|N/A|N/A|N/A|N/A|N/A|N/A|N/A|The state at which the statistic/values are drawn from in each row.|\n",
    "participation_sat_2017|51.0|39.80|35.28|2.0|4.00|38.0|66.00|100.0|1 to 100|Random|The SAT participation rate in 2017 of eligible students in the state.|\n",
    "ebrw_sat_2017|51.0|569.12|45.67|482.0|533.50|559.0|613.00|644.0|200 to 800|Normal, right skewed|The average score across the state for the evidence-based reading and writing section of the SAT in 2017.|\n",
    "math_sat_2017|51.0|556.88|47.12|468.0|523.50|548.0|599.00|651.0|200 to 800|Normal, right skewed|The average score across the state for the math section of the SAT in 2017.|\n",
    "total_sat_2017|51.0|1126.10|92.49|950.0|1055.50|1107.0|1212.00|1295.0|400 to 1600|Normal, right skewed|The average total score across the state for the SAT in 2017|\n",
    "state_act_2017|51.0|N/A|N/A|N/A|N/A|N/A|N/A|N/A|N/A|N/A|The state at which the statistic/values are drawn from in each row.|\n",
    "participation_act_2017|51.0|65.25|32.14|8.0|31.00|69.0|100.00|100.0|1 to 100|Random|The ACT participation rate in 2017 of eligible students in the state.|\n",
    "english_act_2017|51.0|20.93|2.35|16.3|19.00|20.7|23.30|25.5|1 to 36|Normal, right skewed|The average english score across the state for the ACT in 2017.|\n",
    "math_act_2017|51.0|21.18|1.98|18.0|19.40|20.9|23.10|25.3|1 to 36|Normal, right skewed|The average math score across the state for the ACT in 2017.|\n",
    "reading_act_2017|51.0|22.01|2.07|18.1|20.45|21.8|24.15|26.0|1 to 36|Normal, right skewed|The average reading score across the state for the ACT in 2017.|\n",
    "science_act_2017|51.0|21.45|1.74|18.2|19.95|21.3|23.20|24.9|1 to 36|Normal, right skewed|The average science score across the state for the ACT in 2017.|\n",
    "composite_act_2017|51.0|21.52|2.02|17.8|19.80|21.4|23.60|25.5|1 to 36|Normal, right skewed|The average composite score across the state for the ACT in 2017. The composite score is the average score of all sections in the ACT.\n",
    "state_sat_2018|51.0|N/A|N/A|N/A|N/A|N/A|N/A|N/A|N/A|N/A|The state at which the statistic/values are drawn from in each row.|\n",
    "participation_sat_2018|51.0|45.75|37.31|2.0|4.50|52.0|77.50|100.0|1 to 100|Random|The SAT participation rate in 2018 of eligible students in the state.|\n",
    "ebrw_sat_2018|51.0|563.69|47.50|480.0|534.50|552.0|610.50|643.0|200 to 800|Normal, right skewed|The average score across the state for the evidence-based reading and writing section of the SAT in 2018.|\n",
    "math_sat_2018|51.0|556.24|47.77|480.0|522.50|544.0|593.50|655.0|200 to 800|Normal, right skewed|The average score across the state for the math section of the SAT in 2018.|\n",
    "total_sat_2018|51.0|1120.02|94.16|977.0|1057.50|1098.0|1204.00|1298.0|400 to 1600|Normal, right skewed|The average total score across the state for the SAT in 2018|\n",
    "state_act_2018|51.0|N/A|N/A|N/A|N/A|N/A|N/A|N/A|N/A|N/A|The state at which the statistic/values are drawn from in each row.|\n",
    "participation_act_2018|51.0|61.65|34.08|7.0|28.50|66.0|100.00|100.0|1 to 100|Random|The ACT Participatrion rate in 2018 of eligible students in the state.|\n",
    "english_act_2018|51.0|20.99|2.45|16.6|19.10|20.2|23.70|26.0|1 to 36|Normal, right skewed|The average english score across the state for the ACT in 2018.|\n",
    "math_act_2018|51.0|556.24|47.77|480.0|522.50|544.0|593.50|655.0|1 to 36|Normal, right skewed|The average math score across the state for the ACT in 2018.|\n",
    "reading_act_2018|51.0|22.02|2.17|18.0|20.45|21.6|24.10|26.1|1 to 36|Normal, right skewed|The average reading score across the state for the ACT in 2018.|\n",
    "science_act_2018|51.0|21.35|1.87|17.9|19.85|21.1|23.05|24.9|1 to 36|Normal, right skewed|The average science score across the state for the ACT in 2018.|\n",
    "composite_act_2018|51.0|21.49|2.11|17.7|19.95|21.3|23.55|25.6|1 to 36|Normal, right skewed|The average composite score across the state for the ACT in 2018. The composite score is the average score of all sections of the ACT.|\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Distributions in the data\n",
    "\n",
    "In this dataset, each data represents a sample from a population.                        \n",
    "For example, for ACT math test:\n",
    "- Population: the test results of all the students who take this test, nation-wide.\n",
    "- Population mean: is the national average of ACT math test (total scores/total no. of test takers) \n",
    "- Sample: the state means of ACT math test. We have 51 samples (51 states)\n",
    "\n",
    "***According to CLT, we generally assuming that data we sample from a population will be normally distributed. Do we observe this trend?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "According to CLT, we should see a normal distribution if we sample the mean of most populations enough times. Therefore, we should see a normal distribution since the state scores are average scores of the entire population of eligible students. \n",
    "\n",
    "However, the distributions we have seen so far do not perfectly align with a normal distribution. \n",
    "* This could be because we only have n = 51 samples.\n",
    "* This could also be because the samples are not generated randomly, but based on fixed state lines.\n",
    "\n",
    "This may not hold true for participation rates, as many states have high rates in one test and low rates in another. This means that the distribution we see will have peaks at the high and low side of the histogram.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does This Assumption Hold for:\n",
    "    - Math\n",
    "    - Reading\n",
    "    - Rates\n",
    "Explain your answers for each distribution and how you think this will affect estimates made from these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "This assumption will hold true for math and reading scores, but does not apply to participation rates. \n",
    "\n",
    "This is because some states have policies that require students to participate in one of these tests[[1]](#[1]https://www.edweek.org/ew/section/multimedia/states-require-students-take-sat-or-act.html), hence skewing the participation rates for that specific test. When comparing participation rates, one will have to take into account these policies and note that using the mean value may not be the preferred choice.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate Limits of Data\n",
    "\n",
    "Suppose we only seek to understand the relationship between SAT and ACT participation rates in 2017. \n",
    "\n",
    "##### Does it make sense to conduct statistical inference given these data specifically? \n",
    "\n",
    "Why or why not?\n",
    "\n",
    "*(think about granularity, aggregation, the relationships between populations size & rates...consider the actually populations these data describe in answering this question)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "It only makes sense to conduct statistical inference to understand the SAT or ACT participation rates if a state has a 100% participation in either test. This is beacuse statistical inference will get significantly more complex the more we do not understand our data. Since our data is not granular enough, we cannot be certain where is the union or intersection points between students that took the SAT and ACT.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is it appropriate to compare *these* specific SAT and ACT math scores  - can we say students with higher SAT math score is better than those with lower ACT math score, or vice versa?\n",
    "\n",
    "Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "We cannot say that students with higher SAT math scores are better than students with a lower ACT math score, as we do not know the full details of  each student that took the test. This is compounded by the fact that _\"higher scoring states [have] lower participation rates\"_ as _\"Students are not likely to take both the ACT and the SAT unless they know they will score well\"_ [[2]](#[2]https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/). We cannot acccurately make inferences until we have a number of complete datasets (i.e, 100% participation in both ACT and SAT).\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Evaluation of Distributions \n",
    "\n",
    "**If you feel it's appropriate**, using methods we discussed in class, run hypothesis tests to compare variables of interest in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon your observations, choose **three** states that demonstrate interesting trends in their SAT and/or ACT participation rates. Spend some time doing outside research on state policies that might influence these rates, and summarize your findings below. **Feel free to go back and create new plots that highlight these states of interest**. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. (Make sure that you cite your sources -- check with you local instructor for citation preferences)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colorado\n",
    "Colorado is interesting as it had high ACT participation rates in 2017, but not in 2018. Following which, we notice that Colorado also had a high SAT participation rate in 2018. After some digging online, it was found that the reason for this drastic change in participation rates is due to a state policy that required students to take the SAT. This was implemented in the middle of 2017[[3]](#[3]https://www.denverpost.com/2017/03/06/colorado-juniors-sat-college-exam/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing participation rates for Colorado\n",
    "pan_merged_final[pan_merged_final['state_sat_2017'] == 'Colorado']\\\n",
    "[[column for column in pan_merged_final.columns if 'participation' in column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if there are more states like Colorado, we will look for the change in participation rates from 2017 to 2018 for the SAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new dataframe to calculate change in SAT participation rates\n",
    "temp_df = pd.DataFrame(index=pan_merged_final.index, columns=['state','participation_change_sat'])\n",
    "temp_df['participation_change_sat'] = pan_merged_final['participation_sat_2017'] - pan_merged_final['participation_sat_2018']\n",
    "temp_df['state'] = pan_merged_final['state_sat_2017']\n",
    "temp_df.sort_values('participation_change_sat', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying lowest SAT participation rate change\n",
    "temp_df.sort_values('participation_change_sat', ascending = True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that Illinois and Florida also had a large change in SAT participation.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illinois\n",
    "Similar to Colorado, Illinois is interesting as it had high ACT participation rates in 2017, but not in 2018. Following which, we notice that Illinois also had a high SAT participation rate in 2018. After some digging online, it was found that the reason for this drastic change in participation rates is due to a state policy that required students to take the SAT. This was implemented in the middle of 2017[[4]](#[4]https://www.chicagotribune.com/news/ct-illinois-chooses-sat-met-20160211-story.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing participation rates for Illinois\n",
    "pan_merged_final[pan_merged_final['state_sat_2017'] == 'Illinois']\\\n",
    "[[column for column in pan_merged_final.columns if 'participation' in column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Florida\n",
    "Florida is an interesting outlier as it had relatively high participation rates for both tests in 2017, but participation rates significantly dropped in 2018. However with further digging online, it appears that Florida actually achieved a 97% SAT participation rate in 2018[[5]](#[5]https://reports.collegeboard.org/pdf/2018-florida-sat-suite-assessments-annual-report.pdf). This means that the 2018 SAT dataset given is not complete accurate, and will need to be cross-checked with an external source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing participation rates for Florida\n",
    "pan_merged_final[pan_merged_final['state_sat_2017'] == 'Florida']\\\n",
    "[[column for column in pan_merged_final.columns if 'participation' in column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Key takwaways and recommendations:\n",
    "* Work with local policy makers to find out what is stopping them from making the SAT mandatory.\n",
    "    * As shown with Colorado and Illinois, the most effective way to increase participation rate is to make it mandatory for graduating students.\n",
    "    * Questions to ask: Is the ACT already mandatory? If so, why? What does the ACT offer that the SAT does not? Is there any way to leverage on what the SAT does differently?\n",
    "    \n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one state with a lower participation rate and provide a suggestion for how the College Board might increase participation amongst graduating seniors in this state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing states with the lowest participation rates in the SAT\n",
    "pan_merged_final.sort_values('participation_sat_2018', ascending = True)\\\n",
    "[['state_sat_2017','participation_sat_2017','participation_sat_2018','participation_act_2017','participation_act_2018']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "North Dakota has the lowest SAT participation rate out of all the states. After some research, it was found that the ACT is mandatory in North Dakota[[6]](#[6]https://blog.prepscholar.com/which-states-require-the-act-full-list-and-advice). One way that College Board may increase participation amongst graduating seniors is to find out why policy makers have chosen ACT as the mandatory test. \n",
    "\n",
    "Another way that College Board could increase participation rates in North Dakota is to find ways to subsidize the test fees. In Illinois, participation rates dramatically increased once the SAT was subsidized by the state[[4]](#[4]https://www.chicagotribune.com/news/ct-illinois-chooses-sat-met-20160211-story.html). College Board could work with the state to find room in the budget, or an alternative would be to subsidize it themselves to increase participation rates. \n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there additional data you desire that would better inform your investigations?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Information about what % of students in each state took both tests, and also what was the respective average of each score for this group. This will allow us to better understand the relationship between both tests.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "##### [1]https://www.edweek.org/ew/section/multimedia/states-require-students-take-sat-or-act.html\n",
    "##### [2]https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/\n",
    "##### [3]https://www.denverpost.com/2017/03/06/colorado-juniors-sat-college-exam/\n",
    "##### [4]https://www.chicagotribune.com/news/ct-illinois-chooses-sat-met-20160211-story.html\n",
    "##### [5]https://reports.collegeboard.org/pdf/2018-florida-sat-suite-assessments-annual-report.pdf\n",
    "##### [6]https://blog.prepscholar.com/which-states-require-the-act-full-list-and-advice"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
